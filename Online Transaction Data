#Importing Packages
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np



#Task1



#Reading the data from the excel file into a data frame
data = pd.read_csv("/content/gdrive/MyDrive/Colab Notebooks/Online_transaction_data.csv")

#Creating data frames for the normal and unusual data
unusual_data = data.drop(data[data['Type_of_Transaction'] == 'Normal'].index)
normal_data = data.drop(data[data['Type_of_Transaction'] == 'Unusual'].index)


#This will help to view all of the columns when returning a data frame
pd.set_option('display.max_columns', None)

#Look at the data frame for all data
data


#look at information for all data as well as information for the normal and unusual data

data.describe(include='all')
unusual_data.describe(include='all')
normal_data.describe(include='all')

###########################################################################################3

#Task 2



#Renaming columns in the data frame to make them easier to type
cdata = data.rename(columns={'Transaction Time':'Time', 'PCA1':'F1', 'PCA2':'F2', 'PCA3':'F3', 'PCA4':'F4', 'PCA5':'F5',\
                             'PCA6':'F6', 'PCA7':'F7', 'PCA8':'F8', 'PCA9':'F9', 'PCA10':'F10', 'PCA11':'F11', 'PCA12':'F12', \
                             'PCA13':'F13', 'PCA14':'F14', 'PCA15':'F15', 'PCA16':'F16', 'PCA17':'F17', 'PCA18':'F18', \
                             'PCA19':'F19', 'PCA20':'F20', 'PCA21':'F21', 'PCA22':'F22', 'PCA23':'F23', 'PCA24':'F24', \
                             'PCA25':'F25', 'PCA26':'F26', 'PCA27':'F27', 'PCA28':'F28', 'Amount':'Amount', 'Type_of_Transaction':'Type'})

#Changing the order the columns appear in in order to make it easier to look at the "type" column for later visual analysis
cdata = cdata.iloc[:,[0, 29, 30, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28]]

#For ease of training
cdata['Type'].replace({'Unusual':1, 'Normal':0}, inplace=True)

#Creating a clean dataframe that simply ignores the entires with null values
notnull_cdata = cdata.dropna()
notnull_cdata





#Cross chart for correlation
notnull_cdata.corr()




#Task 3 and 4

#Heatmap
plt.figure(figsize=(10, 8))
# Selecting only the relevant columns for correlation analysis
relevant_columns = notnull_cdata.drop(columns=['Amount',  'Time'])
# Plotting the correlation heatmap
sns.heatmap(relevant_columns.corr(), cmap='coolwarm', annot=False)
plt.title('Correlation Heatmap')
plt.xlabel('Features')
plt.ylabel('Features')
plt.show()




#Box Plot

# Drop 'Time', 'Amount', and 'Type' columns
noclassify_notnull_cdata = notnull_cdata.drop(columns=['Time', 'Amount', 'Type'])

# Set up the plot and adjust the scale of the y-axis
plt.figure(figsize=(12, 6))
sns.boxplot(data=noclassify_notnull_cdata)
plt.ylim(-150, 150)  # Adjust the y-axis limit for better visualization

# Add title and labels
plt.title('Boxplot of Features')
plt.xlabel('Features')
plt.ylabel('Values')

# Rotate x-axis labels for better readability
plt.xticks(rotation=45)

# Add grid lines
plt.grid(True)

# Show plot
plt.show()







#Adding an avg column as entry Average has a relatively strong correlation to "Type"
df = notnull_cdata.drop(columns=['Type', 'Time', 'Amount']) #Remove elements that throw it off and "Type" as it will obviously be correlated to itself
df.insert(0, 'Average', df.mean(axis=1))
type_df = notnull_cdata['Type']
df.insert(0, 'Type', type_df)

#We can also take a selective average of the most closely correlated features
d = {'F12':df['F12'], 'F14':df['F14'], 'F17':df['F17']}
df1 = pd.DataFrame(data=d)
#df1.mean(axis=1)

df2 = df.copy()
df2.insert(2, 'Select avg', df1.mean(axis=1))
df2.corr()


#Heatmap
fig, ax = plt.subplots(figsize=(10,8))
sns.heatmap(df2.corr(), cmap='coolwarm', ax=ax)
plt.show()






####################################################################################################################################################################################################################################
#Since we need a proper model I will be choosing features f10, 12, 14, 17
#These features allow for higher accuracy, precision, and recall scores



"4. Model instantiation and training"

# Import libraries
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB





# Split data into features (X) and target variable (y)
X = notnull_cdata.loc[:, ['F12', 'F14', 'F17']]
y = type_df.values




# Split the data into training(30 percent) and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Reshape X_train if it has only one feature
if X_train.ndim == 1:
    X_train = X_train.values.reshape(-1, 1)

# Build and train models
dt_model = DecisionTreeClassifier()
dt_model.fit(X_train, y_train)

rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)

lr_model = LogisticRegression()
lr_model.fit(X_train, y_train)

svm_model = SVC()
svm_model.fit(X_train, y_train)

nb_model = GaussianNB()
nb_model.fit(X_train, y_train)





"5. Model Evaluation"

# Import libraries
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Make predictions
dt_preds = dt_model.predict(X_test)
rf_preds = rf_model.predict(X_test)
lr_preds = lr_model.predict(X_test)
svm_preds = svm_model.predict(X_test)
nb_preds = nb_model.predict(X_test)

# Calculate and print metrics for Decision Tree model
print("Decision Tree Metrics:")
print("Accuracy:", accuracy_score(y_test, dt_preds))
print("Precision:", precision_score(y_test, dt_preds))
print("Recall:", recall_score(y_test, dt_preds))
print("F1 Score:", f1_score(y_test, dt_preds))

# Calculate and print metrics for Random Forest model
print("Random Forest Metrics:")
print("Accuracy:", accuracy_score(y_test, rf_preds))
print("Precision:", precision_score(y_test, rf_preds))
print("Recall:", recall_score(y_test, rf_preds))
print("F1 Score:", f1_score(y_test, rf_preds))

# Calculate and print metrics for Logistic Regression model
print("Logistic Regression Metrics:")
print("Accuracy:", accuracy_score(y_test, lr_preds))
print("Precision:", precision_score(y_test, lr_preds))
print("Recall:", recall_score(y_test, lr_preds))
print("F1 Score:", f1_score(y_test, lr_preds))

# Calculate and print metrics for SVM model
print("SVM Metrics:")
print("Accuracy:", accuracy_score(y_test, svm_preds))
print("Precision:", precision_score(y_test, svm_preds))
print("Recall:", recall_score(y_test, svm_preds))
print("F1 Score:", f1_score(y_test, svm_preds))

# Calculate and print metrics for Naive Bayes model
print("Naive Bayes Metrics:")
print("Accuracy:", accuracy_score(y_test, nb_preds))
print("Precision:", precision_score(y_test, nb_preds))
print("Recall:", recall_score(y_test, nb_preds))
print("F1 Score:", f1_score(y_test, nb_preds))
